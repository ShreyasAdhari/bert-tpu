{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "bert-tpu-1",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "435b9950d309461eab485ecd66f45f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad2d2c8226d445c580c87408ed76a0c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_993842b7cfbe49a492ad5eb0c4b73d76",
              "IPY_MODEL_aab684864c1245b783311681593397fd",
              "IPY_MODEL_5edb7da081d9497399ad758ce949f5f2"
            ]
          }
        },
        "ad2d2c8226d445c580c87408ed76a0c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "993842b7cfbe49a492ad5eb0c4b73d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ccff38da46844aeb17375bea02eef93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a9baf671da846fa8ba5096b8dfd6231"
          }
        },
        "aab684864c1245b783311681593397fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e4f0743c9bf44211885f1e4b4c09da50",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdcd7f6d7b6649a9b488d7bf1d51a828"
          }
        },
        "5edb7da081d9497399ad758ce949f5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f76048cbcc0c4ad58df04d9cb6b47cd9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 538B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a411b510326846deb1540201d1692f89"
          }
        },
        "2ccff38da46844aeb17375bea02eef93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a9baf671da846fa8ba5096b8dfd6231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4f0743c9bf44211885f1e4b4c09da50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdcd7f6d7b6649a9b488d7bf1d51a828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f76048cbcc0c4ad58df04d9cb6b47cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a411b510326846deb1540201d1692f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMGufbR4zO_1",
        "outputId": "6e7b42c9-a119-42cc-e434-ed971e225452"
      },
      "source": [
        "# !mkdir ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !kaggle competitions download -c amazon-pet-product-reviews-classification\n",
        "# !unzip \\*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading unlabeled.csv.zip to /content\n",
            "100% 17.0M/17.0M [00:01<00:00, 12.1MB/s]\n",
            "100% 17.0M/17.0M [00:01<00:00, 12.6MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/176k [00:00<?, ?B/s]\n",
            "100% 176k/176k [00:00<00:00, 126MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            "  0% 0.00/2.98M [00:00<?, ?B/s]\n",
            "100% 2.98M/2.98M [00:00<00:00, 48.6MB/s]\n",
            "Downloading valid.csv.zip to /content\n",
            "  0% 0.00/3.00M [00:00<?, ?B/s]\n",
            "100% 3.00M/3.00M [00:00<00:00, 48.5MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 56% 5.00M/8.88M [00:00<00:00, 16.5MB/s]\n",
            "100% 8.88M/8.88M [00:00<00:00, 25.4MB/s]\n",
            "Archive:  valid.csv.zip\n",
            "  inflating: valid.csv               \n",
            "\n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "\n",
            "Archive:  unlabeled.csv.zip\n",
            "  inflating: unlabeled.csv           \n",
            "\n",
            "4 archives were successfully processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-06T18:02:37.212492Z",
          "iopub.execute_input": "2021-10-06T18:02:37.212860Z",
          "iopub.status.idle": "2021-10-06T18:03:35.884295Z",
          "shell.execute_reply.started": "2021-10-06T18:02:37.212770Z",
          "shell.execute_reply": "2021-10-06T18:03:35.883163Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ikt2GSx1ZF",
        "outputId": "ec58f2a7-a527-4652-f604-a648cd1f4a8b"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5116  100  5116    0     0  12210      0 --:--:-- --:--:-- --:--:-- 12180\n",
            "Updating... This may take around 2 minutes.\n",
            "Found existing installation: torch 1.9.0+cu102\n",
            "Uninstalling torch-1.9.0+cu102:\n",
            "  Successfully uninstalled torch-1.9.0+cu102\n",
            "Found existing installation: torchvision 0.10.0+cu102\n",
            "Uninstalling torchvision-0.10.0+cu102:\n",
            "  Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "\\ [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "| [1 files][119.5 MiB/119.5 MiB]                                                \n",
            "Operation completed over 1 objects/119.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "- [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20200515) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20200515) (0.16.0)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 1.0.61 requires torchvision, which is not installed.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0a0+bf2bbd9\n",
            "Processing ./torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+2b2085a\n",
            "Processing ./torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==nightly+20200515) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+a6073f0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 2s (144 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uduvVdb0FFED"
      },
      "source": [
        "!pip install torchmetrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z15QbSX65xfG",
        "outputId": "d3f187be-ad70-4ad8-9218-d85133a5323d"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.19 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMixa2Ck43yv"
      },
      "source": [
        "import torch_xla\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPZLHMvX5gQv"
      },
      "source": [
        "import os\n",
        "os.environ['XLA_USE_BF16']                 = '1'\n",
        "os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '1000000000'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IifklCTa5i0u"
      },
      "source": [
        "from transformers import AutoTokenizer,AutoConfig,AutoModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import numpy as np\n",
        "from torchmetrics.functional import f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzJuY6qH-y3X"
      },
      "source": [
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR6Vq3cr5-zG"
      },
      "source": [
        "chk = 'distilbert-base-uncased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp_D5UhP5__u"
      },
      "source": [
        "class BertDataset(Dataset):\n",
        "\n",
        "  def __init__(self,x,labels,tokenizer,max_len=256,test=False):\n",
        "\n",
        "    self.x = x\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = 512\n",
        "    self.test = test\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "\n",
        "    tokens = self.tokenizer.encode_plus(\n",
        "        self.x[index],\n",
        "        add_special_tokens = True,\n",
        "        max_length = self.max_len,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    pad = self.max_len - tokens['input_ids'].squeeze(0).size(0)\n",
        "\n",
        "    input_ids = tokens['input_ids'].squeeze(0)\n",
        "    attention_mask = tokens['attention_mask'].squeeze(0)\n",
        "\n",
        "    del tokens\n",
        "\n",
        "    if pad > 0:\n",
        "\n",
        "      input_ids = torch.cat( [ input_ids , torch.Tensor( [ self.tokenizer.pad_token_id ]*pad ) ] )\n",
        "      attention_mask = torch.cat( [ attention_mask , torch.Tensor([0]*pad ) ] )\n",
        "    \n",
        "    if self.test:\n",
        "\n",
        "      return input_ids,attention_mask\n",
        "    \n",
        "    else : return input_ids,attention_mask,torch.Tensor([self.labels[index]])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndr_q7Jb6Bpm"
      },
      "source": [
        "train = pd.read_csv('/content/train.csv',index_col='id')\n",
        "validate = pd.read_csv('/content/valid.csv',index_col='id')\n",
        "test = pd.read_csv('/content/test.csv',index_col='id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R90T-x7SOA9F"
      },
      "source": [
        "xtr,ytr = train['text'],train['label']\n",
        "xva,yva = validate['text'],validate['label']\n",
        "xte = test['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezy4iiSIM-Fy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "435b9950d309461eab485ecd66f45f79",
            "ad2d2c8226d445c580c87408ed76a0c6",
            "993842b7cfbe49a492ad5eb0c4b73d76",
            "aab684864c1245b783311681593397fd",
            "5edb7da081d9497399ad758ce949f5f2",
            "2ccff38da46844aeb17375bea02eef93",
            "7a9baf671da846fa8ba5096b8dfd6231",
            "e4f0743c9bf44211885f1e4b4c09da50",
            "bdcd7f6d7b6649a9b488d7bf1d51a828",
            "f76048cbcc0c4ad58df04d9cb6b47cd9",
            "a411b510326846deb1540201d1692f89",
            "3b97db1035a44016b7eb5f52ebcf36b5",
            "df1283d7645b4aee9a5e9dd03734a675",
            "37f7105656db435bb682bf229cec3351"
          ]
        },
        "outputId": "1e9aedc7-c35a-4002-de64-f0d1e7d9efa8"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(chk)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "435b9950d309461eab485ecd66f45f79",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b97db1035a44016b7eb5f52ebcf36b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df1283d7645b4aee9a5e9dd03734a675",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37f7105656db435bb682bf229cec3351",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6rDu3RmOTIS"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ee8VQkaOYo7"
      },
      "source": [
        "le = LabelEncoder()\n",
        "ytr = le.fit_transform(ytr)\n",
        "yva = le.transform(yva)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC9XhJ7L6d4d"
      },
      "source": [
        "class BertForClassification(nn.Module):\n",
        "\n",
        "  def __init__(self,num_classes):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    config = AutoConfig.from_pretrained(chk,num_labels=num_classes)\n",
        "\n",
        "    self.transformer = AutoModel.from_pretrained(chk,config=config)\n",
        "    self.preclf = nn.Linear(config.dim,config.dim)\n",
        "    self.classifier = nn.Linear(config.dim,num_classes)\n",
        "\n",
        "  \n",
        "  def forward(self,input_ids,attention_mask,head_mask=None):\n",
        "\n",
        "    out = self.transformer(input_ids=input_ids,attention_mask=attention_mask,head_mask=head_mask)[0]\n",
        "    out = self.preclf(out[:,0,:])\n",
        "    out = self.classifier(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwPtbUxdh-ZN"
      },
      "source": [
        "def collate_fn(batch):\n",
        "\n",
        "  input_ids,attention_mask,labels = tuple(zip(*batch))\n",
        "\n",
        "  input_ids = torch.stack(input_ids).long()\n",
        "  attention_mask = torch.stack(attention_mask).int()\n",
        "  labels = torch.stack(labels).squeeze().long()\n",
        "\n",
        "  return {'input_ids':input_ids,'attention_mask':attention_mask},labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7HJ0TnC0n-0"
      },
      "source": [
        "class config:\n",
        "\n",
        "  lr = 5e-5\n",
        "  opt = transformers.AdamW\n",
        "  opt_params = {}\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss\n",
        "  criterion_params = {}\n",
        "\n",
        "  scheduler = None\n",
        "  validation_schduler = None\n",
        "  step_scheduler = None\n",
        "\n",
        "  epochs = 1\n",
        "\n",
        "  metrics = [f1]\n",
        "  metrics_names = ['loss','f1_score']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uQIidSw3qYc"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teDscVTP9DYE"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZchzXw_Ox1ZN"
      },
      "source": [
        "class TPUFitter():\n",
        "\n",
        "  def __init__(self,model,config,device):\n",
        "\n",
        "    self.model = model\n",
        "    self.device = device\n",
        "    self.config = config\n",
        "\n",
        "\n",
        "    self.epoch = 0\n",
        "\n",
        "    self.criterion = self.config.criterion(**self.config.criterion_params)\n",
        "\n",
        "    param_optimizer = list(self.model.named_parameters())\n",
        "    \n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "    \n",
        "    self.opt = self.config.opt( optimizer_grouped_parameters , lr=self.config.lr*xm.xrt_world_size(), **self.config.opt_params )\n",
        "    \n",
        "    if self.config.scheduler is not None:\n",
        "      self.scheduler = self.config.scheduler(self.opt,**self.config.scheduler_params)\n",
        "    else : self.scheduler = None\n",
        "    \n",
        "    self.best_loss = 10**5\n",
        "\n",
        "    xm.master_print(f'Fitter prepared. Device is {self.device}')\n",
        "  \n",
        "  def log(self,x):\n",
        "    xm.master_print(x)\n",
        "  \n",
        "  def fit(self,train_loader,validate_loader):\n",
        "\n",
        "    for epoch in range(self.config.epochs):\n",
        "\n",
        "      st = time.time()\n",
        "      para_loader = pl.ParallelLoader(train_loader,[self.device])\n",
        "      train_metrics = self.train_one_epoch(para_loader.per_device_loader(self.device))\n",
        "      s = '[TRAIN] '+f' Epoch : {epoch} ' +'   '.join(f\" {k} : {v} \" for k,v in zip(train_metrics,self.config.metrics_names) ) + f' Time : {int(time.time()-st)}'\n",
        "      self.log(s)\n",
        "      del para_loader\n",
        "      gc.collect()\n",
        "\n",
        "      st = time.time()\n",
        "      para_loader = pl.ParallelLoader(validate_loader,[self.device])\n",
        "      validate_metrics = self.validate(para_loader.per_device_loader(self.device))\n",
        "      s = '[VALID] '+f' Epoch : {epoch} ' +'   '.join(f\" {k} : {v} \" for k,v in zip(validate_metrics,self.config.metrics_names) ) + f' Time : {int(time.time()-st)}'\n",
        "      self.log(s)\n",
        "      del para_loader\n",
        "      gc.collect()\n",
        "\n",
        "      if ( self.scheduler is not None )  and ( self.config.validation_scheduler is not None ) :\n",
        "        self.scheduler.step(metrics=validate_metrics[0])\n",
        "      \n",
        "  \n",
        "  def validate(self,validate_loader):\n",
        "\n",
        "    avg_loss = AverageMeter()\n",
        "    avg_loss.reset()\n",
        "    mets = [avg_loss]\n",
        "\n",
        "    if len(self.config.metrics) > 1:\n",
        "      for m in self.config.metrics:\n",
        "        ms = AverageMeter()\n",
        "        ms.reset()\n",
        "        mets.append(ms)\n",
        "      \n",
        "    \n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for bi,(x,y) in enumerate(validate_loader):\n",
        "\n",
        "        for k,v in x:\n",
        "          x[k] = v.to(self.device)\n",
        "        \n",
        "        y = y.to(self.device)\n",
        "        \n",
        "        out = self.model(**x)\n",
        "        loss = self.criterion(out,y)\n",
        "\n",
        "        bs = y.shape[0].item()\n",
        "\n",
        "        mets[0].update(loss.detach().item(),bs)\n",
        "        \n",
        "        \n",
        "        if len (mets) > 1 :\n",
        "          for m,meter in zip ( self.config.metrics[1: ],mets[1:] ) :\n",
        "            sc = m( torch.max(out,dim=-1)[1], y )\n",
        "            meter.update(sc.item(),bs)\n",
        "            del sc\n",
        "            gc.collect()\n",
        "        \n",
        "        del loss,out,x,y\n",
        "        gc.collect()\n",
        "    \n",
        "\n",
        "    return [ m.avg for m in mets ]\n",
        "  \n",
        "  def train_one_epoch(self,train_loader):\n",
        "\n",
        "    avg_loss = AverageMeter()\n",
        "    avg_loss.reset()\n",
        "    mets = [avg_loss]\n",
        "\n",
        "    if len(self.config.metrics) > 1:\n",
        "      for m in self.config.metrics:\n",
        "        ms = AverageMeter()\n",
        "        ms.reset()\n",
        "        mets.append(ms)\n",
        "    \n",
        "\n",
        "    for i,(x,y) in enumerate(train_loader):\n",
        "\n",
        "      for k,v in x:\n",
        "          x[k] = v.to(self.device)\n",
        "      \n",
        "      y = y.to(self.device)\n",
        "      \n",
        "      bs = y.shape[0].item()\n",
        "        \n",
        "      out = self.model(**x)\n",
        "      loss = self.criterion(out,y)\n",
        "\n",
        "      self.opt.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      mets[0].update(loss.detach().item(),bs)\n",
        "        \n",
        "        \n",
        "      if len (mets) > 1 :\n",
        "        for m,meter in zip ( self.config.metrics[1: ],mets[1:] ) :\n",
        "          sc = m( torch.max(out,dim=-1)[1], y )\n",
        "          meter.update(sc.item(),bs)\n",
        "          del sc\n",
        "          gc.collect()\n",
        "      \n",
        "      xm.optimizer_step(self.opt)\n",
        "\n",
        "      del loss,out,x,y\n",
        "\n",
        "      if ( self.scheduler is not None ) and ( self.config.step_scheduler is not None):\n",
        "        self.scheduler.step()\n",
        "    \n",
        "\n",
        "    return [ m.avg for m in mets]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRxH18PaEvoM"
      },
      "source": [
        "def _mp_fn(ranks,flags):\n",
        "\n",
        "  device = xm.xla_device()\n",
        "  model.to(device)\n",
        "\n",
        "  train_data = BertDataset(xtr,ytr,tokenizer)\n",
        "  validate_data = BertDataset(xva,yva,tokenizer)\n",
        "\n",
        "  train_sampler = torch.utils.data.DistributedSampler(train_data,num_replicas=xm.xrt_world_size(),rank=xm.get_ordinal())\n",
        "  validate_sampler = torch.utils.data.DistributedSampler(validate_data,num_replicas=xm.xrt_world_size(),rank=xm.get_ordinal())\n",
        "\n",
        "  train_loader = DataLoader(train_data,batch_size=bs,shuffle=True,sampler=train_sampler,pin_memory=True,drop_last=True)\n",
        "  validate_loader = DataLoader(validate_data,batch_size=bs,shuffle=False,sampler=validate_sampler,pin_memory=True,drop_last=False)\n",
        "\n",
        "  fitter = TPUFitter(model,config,device)\n",
        "\n",
        "  if rank == 0 :\n",
        "    time.sleep(1)\n",
        "  \n",
        "  fitter.fit(train_loader,validate_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mfCKXljIfPk"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "v01fysgVIVQM",
        "outputId": "64528d1d-97c0-44e6-8553-48c422c7b4ce"
      },
      "source": [
        "model = BertForClassification(len(le.classes_))\n",
        "FLAGS={}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-0a7f48152e13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mp_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_xla_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# If this is not an XLA setup, jump to normal multi-processing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_run_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m   \u001b[0mpf_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pre_fork_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnprocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36m_run_direct\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    243\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     return torch.multiprocessing.spawn(\n\u001b[0;32m--> 245\u001b[0;31m         fn, args=args, nprocs=nprocs, join=join, daemon=daemon)\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    198\u001b[0m                ' torch.multiprocessing.start_process(...)' % start_method)\n\u001b[1;32m    199\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 raise Exception(\n\u001b[1;32m    112\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 )\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: process 0 terminated with exit code 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk7BLCC2Ig6D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}